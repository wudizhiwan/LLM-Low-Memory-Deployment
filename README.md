# 大模型低内存运行架构设计
通过模拟虚拟内存结构构建系统，为大语言模型（如deepseek）开发一个专用的低内存运行环境
## 项目名称
基于专用虚拟内存结构的大模型低内存运行系统

## 项目描述
大尺寸模型（如70B、671B等）的参数量极大，传统内存管理模式难以在有限物理内存下完整部署模型。本项目旨在构建一套类似虚拟内存的专用结构，通过数据按需加载与智能数据交换，在降低内存占用的同时实现完整运行DeepSeek大尺寸模型，确保系统连续高效运行。

## 项目特征
1. 构建面向大模型参数的**专用内存管理系统**，实现数据按需加载、智能淘汰和多级缓存，降低内存占用。

2. 分析模型内存访问模式，设计**动态调度算法**，智能区分高频与低频参数块，实现最优资源利用。

3. 采用非侵入式方式**兼容主流大模型框架**，并提供实时可视化监控与自动化测试手段，确保系统调优和性能验证。

## 预期目标

### 1. **降低内存占用：**  
  - **按需加载：** 实现参数数据的动态加载，确保只在必要时将数据调入内存。  
  - **智能淘汰：** 根据使用频率和优先级自动淘汰低频数据，释放宝贵内存资源。  
  - **多级缓存：** 设计分级缓存策略，使得热点数据可以在高速缓存中快速访问，而冷数据则存储于次级缓存或外部存储。

### 2. **保持高效性能：**  
  - **低延迟：** 通过优化数据调度策略，确保参数加载过程对整体计算延迟的影响降到最低。  
  - **高吞吐量：** 实现并发数据调度，支持多线程或分布式环境下的高效参数交换。  
  - **连续计算：** 在数据交换过程中保证计算任务的连续性，避免因数据调入过程引入瓶颈。

### 3. **可量化验证：**  
  - **实时监控：** 构建可视化监控平台，实时展示内存占用、数据加载状态和调度情况。  
  - **基准测试：** 制定标准化的测试方案，通过对比实验验证系统在内存利用率和计算性能上的提升。  
  - **数据日志：** 收集详细运行日志，为系统优化和问题排查提供量化依据。

## 参考资料
**相关工具**  

- [llama.cpp](https://github.com/ggerganov/llama.cpp)  
- [TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM)  
- [vLLM](https://github.com/vllm-project/vllm)
- 其他大模型和内存调度相关开源项目及工具链

## 所属赛道
2025全国大学生操作系统比赛 —— “OS功能设计”赛道

## 难度
中等

## 项目导师
- 姓名：宫晓利  
- 单位：南开大学  
- Email: gongxiaoli@nankai.edu.cn
